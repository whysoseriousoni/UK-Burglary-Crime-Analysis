{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8972cd",
   "metadata": {},
   "source": [
    "# Big Data Product: Burglary Protection \n",
    "\n",
    "In this scenario, you are a data scientist working with a marketing consultancy. Your client is an insurance company that is developing a highly segmented home insurance product.\n",
    "\n",
    "Since it is hypothesized that customers who live in an area where burglary is prevalent would be more interested in a new insurance policy, the company would like to find out whether \"Burglary\" is more frequent in particular areas of England. \n",
    "\n",
    "If that is the case the company needs to determine whether these are arcas of affluence, where a premium policy with high benefits could be sold, or one of relative deprivation where a low-cost economic policy with proportionately lower pay-outs would be more appropriate. Furthermore, the company would like to target areas where burglary is known to be increasing The questions to be answered are whether:\n",
    "1. There are more burglaries in more affluent areas\n",
    "2. Burglaries are increasing, decreasing, or are stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0df16bb",
   "metadata": {},
   "source": [
    "### To solve this problem, you will use publicly available data sets that have been prepared for you and placed online. These include (but are not limited to):-\n",
    "\n",
    "1.\tStreet Level Crime Data published by the UK Home Office, this dataset contains 19 million data rows giving a crime type, together with their location as a latitude and longitude.\n",
    "2.\tEnglish Indices of Deprivation Data: The English Indices of Deprivation 2010 data set contains the rankings of measures of deprivation within small area level across England. The 32000 localities are ranked from the least to most deprived, scored on seven different dimensions of deprivation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c42d0",
   "metadata": {},
   "source": [
    "# Assignment Specifics\n",
    "\n",
    "1.\tProcess the given data efficiently using Apache Spark on a cloud Infrastructure as a Service (IaaS) platform. A sample Jupyter Notebook has been provided on Blackboard.\n",
    "2.\tFilter the dataset so that only relevant crimes are included.\n",
    "3.\tUsing appropriate techniques, determine whether Burglaries are increasing, decreasing, or are stable.\n",
    "4.\tUsing appropriate techniques, determine whether Burglary is more closely associated with areas of high affluence, relative deprivation or neither\n",
    "5.\tSelect and prepare no more than four visualizations to support your analytic findings from (3).\n",
    "6.\tExplain the reasoning behind your code so that it is clear what each block is intended to achieve (i.e., appropriately comment the command line).\n",
    "8.\tAssess the two claims given and determine whether they are true, false, or cannot be determined.\n",
    "9.\tCritically assess and report on the advantages, disadvantages, and limitations of the methods used. \n",
    "10.\tYour submission will be a Jupyter Notebook containing both code (typically Python), and explanatory text (in Markdown format) limited to 2500 words (plus references). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651d244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "937f5ae2",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "## The Burglary Crime Analysis task and Approach taken to the problem\n",
    "\n",
    "##### Crimes in general is a huge problem for society, peace of mind, locality and affects various parts of life for many people.\n",
    "\n",
    "#### Burglary Crime Introduction\n",
    "\n",
    "\n",
    "In recent years, there has been a growing interest in understanding the spatial distribution of crime, particularly burglary, across different regions in England. This is important for various stakeholders, including insurance companies, as it helps them develop targeted products and services. For instance, a highly segmented home insurance product can be tailored to areas with high burglary rates to offer better coverage and protection for the residents. To achieve this, we will examine available data sources such as the Office for National Statistics (ONS) and UK Police Crime Data to identify areas with higher burglary prevalence and understand their socio-economic characteristics (Office for National Statistics, 2021; Police UK, 2021). By determining whether these areas are affluent or relatively deprived, we can help the insurance company design appropriate policies that cater to the specific needs and preferences of the customers in those areas.\n",
    "\n",
    "To accomplish this, present study will leverage available data sources such as the Office for National Statistics (ONS), UK Police Crime Data, and other government sources to obtain accurate and up-to-date crime data. Through a combination of statistical analysis, data visualization, and clustering algorithms, we will deliver actionable insights that will help our client create a targeted and effective home insurance product for the English market.\n",
    "\n",
    "\n",
    "#### Approach taken\n",
    "* Using Big data processing tool (PySpark) running in cloud infrastructure IAAS (like AWS ec2) or PAAS (like AWS Glue or Azure Data Factory)\n",
    "* The analysis is to study burglary crimes happening in United Kingom (UK) between time period Dec-2010 to April-2020 \n",
    "* Using various statistical & visualization techniques we study trends and assert various claims by Insurance Client.\n",
    "* How are we doing the analysis?\n",
    "   1. Use PySpark to process & crunch the data for better handling of raw data (~19MM rows)\n",
    "   2. Look at various visual lenses to translate the data into more digestable \n",
    "   3. Apply statistical methods to help to test various hypothesis & claims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b89da",
   "metadata": {},
   "source": [
    "#### Difference beween IAAS and PAAS \n",
    "|Index|Topic|IAAS|PAAS|\n",
    "|---|---|---|---|\n",
    "|0|Where it runs?|Runs in any cloud computer or virtual machine or computer |Underlying architecture is already handled by |\n",
    "|1|Who is going to Setup?|User needs to setup with packages required|Setup is already done|\n",
    "|2|Customizability|Very modular & highly customizable|Less customizability|\n",
    "|3|Is it easy to setup?| Setting up requires time| Does not require much time like IAAS|\n",
    "|4|Can I interact & debug?|Run a server & work in jupyter notebook, helps run things interactively & debug each step|Debugging option is highly reduced. All the visuals generated needs to be saved before viewing|\n",
    "|5|Examples|AWS EC2, Azure Virtual Machines|AWS Glue job, Azure Data Factory|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755bf4de",
   "metadata": {},
   "source": [
    "## 2. Component Selection and Data Pipeline Implementation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78017ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0daf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Importing Packages\n",
    "    Packages are categorized into groups based on their functionality & usage\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Big Data Packages\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "## Spark Data types\n",
    "from pyspark.sql.types import (StructType, StructField, StringType, BooleanType, FloatType, TimestampType, DoubleType, DateType, IntegerType)\n",
    "\n",
    "## Spark Functions\n",
    "from pyspark.sql.functions import (col, when, desc, udf) # Selectors\n",
    "from pyspark.sql.functions import (count, isnull, sum, mean, variance, stddev, percentile_approx, countDistinct) # Data Manipulation\n",
    "import pyspark.sql.functions as psf\n",
    "\n",
    "# Visualization Packages\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Map Visualization\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap, HeatMapWithTime\n",
    "\n",
    "\n",
    "# Data Manipulation Packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Modelling Packages\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Additional Packages\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# Styling\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a16dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuring Jupyter environment\n",
    "    Ignore warnings caused by depricated package\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "# Visualization Figure Size\n",
    "plt.rcParams['figure.figsize'] = [18, 8] # [width, height]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d2907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Creating Spark Session for data processing & Configuring Spark\n",
    "\n",
    "Spark Configuration: \n",
    "\n",
    "    spark.sql.repl.eagerEval.enabled -> \n",
    "        Displays spark dataframe in table (like pandas table out) instead printing\n",
    "\n",
    "\n",
    "    spark.sql.execution.arrow.pyspark.enabled -> (For Spark version 3.x.x)\n",
    "        Apache Arrow is an in-memory columnar data format to efficiently transfer data between JVM and Python processes. \n",
    "        This is most beneficial to users that work with Pandas/NumPy data\n",
    "\n",
    "    spark.sql.execution.arrow.enabled -> (For Spark version 2.x.x) \n",
    "        Deprecated, and maybe removed in future. Using this incase `spark.sql.execution.arrow.enabled` fails to load\n",
    "        Apache Arrow is an in-memory columnar data format to efficiently transfer data between JVM and Python processes. \n",
    "        This is most beneficial to users that work with Pandas/NumPy data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Finding Spark\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('Spark')\\\n",
    "                                    .config('spark.sql.repl.eagerEval.enabled',True)\\\n",
    "                                    .config('spark.sql.execution.arrow.enabled', True)\\\n",
    "                                    .config('spark.sql.execution.arrow.pyspark.enabled',True)\\\n",
    "                                    .config(\"spark.driver.memory\", \"15g\")\\\n",
    "                                    .enableHiveSupport().getOrCreate()\n",
    "\n",
    "# Getting Spark Session\n",
    "spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d57404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aefb51c5",
   "metadata": {},
   "source": [
    "## 3. Data Extraction and Filtering System running, test and diagnostics\n",
    "\n",
    "#### Given Specifics:\n",
    "\n",
    "2.\tFilter the dataset so that only relevant crimes are included.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functions to optimize code reusability\n",
    "\n",
    "def checkCountDifference(spark_df, name):\n",
    "    '''\n",
    "    prints:\n",
    "        for each column in spark dataframe:\n",
    "            Count of values (nulls excluded), Count of null values (#of rows in spark dataframe - count of column)\n",
    "    '''\n",
    "    print(f'Checking for missing values : {name}')\n",
    "    for column_ in spark_df.columns:\n",
    "        res = spark_df.select(count(col(column_)).alias('count'))\n",
    "        count_ = res.collect()[0]['count']\n",
    "        print(f'Column: {column_} | Count: {count_} | Missing: {spark_df.count()-count_}')\n",
    "\n",
    "def renameColumns(spark_df):\n",
    "    '''\n",
    "    Renames Spark dataframe columns with ALL_CAPITAL & `_` separated instead of space ` `\n",
    "    \n",
    "    '''\n",
    "    for old_column_name in spark_df.columns:\n",
    "        spark_df = spark_df.withColumnRenamed(old_column_name, old_column_name.upper().replace(' ','_'))\n",
    "    return spark_df\n",
    "\n",
    "\n",
    "def stylePandasDataframe(df):\n",
    "    '''\n",
    "    Pandas dataframe styler. Prints dataframe in a grid format\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    style = df.style.set_table_styles(\n",
    "        [{\"selector\": \"\", \"props\": [(\"border\", \"1px solid grey\")]},\n",
    "          {\"selector\": \"tbody td\", \"props\": [(\"border\", \"1px solid grey\")]},\n",
    "         {\"selector\": \"th\", \"props\": [(\"border\", \"1px solid grey\")]}\n",
    "        ]\n",
    "    )\n",
    "    return HTML(style.render())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functions for Visualization \n",
    "# Every function below have args:dict as parameter -> which will be unpacked inside the function\n",
    "\n",
    "def plotlyTreeMap(dataframe, args) -> None:\n",
    "    '''\n",
    "    Plots and displays a tree map \n",
    "    Why we are using Tree Map with 0 depth?\n",
    "        This way, it helps us in visualize proportion in a sorted manner \n",
    "        \n",
    "    '''\n",
    "    fig = px.treemap(dataframe, color_discrete_sequence=px.colors.sequential.RdBu, color_continuous_scale='RdBu', **args)\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def plotlyBar(dataframe, args):\n",
    "    '''\n",
    "    Plots and displays interactable Bar chart\n",
    "    \n",
    "    '''\n",
    "    fig = px.bar(dataframe, **args)\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def plotlyLine(dataframe, args):\n",
    "    '''\n",
    "    Plots and displays interactable Line chart\n",
    "    \n",
    "    '''\n",
    "    fig = px.line(dataframe, **args)\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca56b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Loading Data \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "crimes_df = spark.read.csv(path=r'all_crimes21_hdr.txt'\n",
    "                                 , header=True\n",
    "                                 , inferSchema=True)\n",
    "\n",
    "# Renaming columns to minimize errors while referencing columns \n",
    "crimes_df = renameColumns(crimes_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Feature engineering\n",
    "1. We need Area name to know events at aggregated level. \n",
    "    With use of LSOA_NAME, we can extract AREA_NAME by removing last 5 characters\n",
    "\n",
    "2. Extract Month and Year from the Timestamp\n",
    "\n",
    "'''\n",
    "## Extracting Area name from LSOA Name\n",
    "crimes_df = crimes_df.withColumn('AREA_NAME', psf.expr(\"substring(LSOA_NAME, 1, length(LSOA_NAME)-5)\"))\n",
    "\n",
    "\n",
    "## Extracting month & year from timestamp\n",
    "crimes_df = crimes_df.withColumn('EXTRACTED_MONTH', psf.expr(\"month(MONTH)\"))\n",
    "crimes_df = crimes_df.withColumn('YEAR', psf.expr(\"year(MONTH)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf7f4b",
   "metadata": {},
   "source": [
    "## 4. Design, Development and reasoning behind use of multiple visualization methods, statistics, and machine learning Models\n",
    "\n",
    "3.\tUsing appropriate techniques, determine whether Burglaries are increasing, decreasing, or are stable.\n",
    "4.\tUsing appropriate techniques, determine whether Burglary is more closely associated with areas of high affluence, relative deprivation or neither\n",
    "5.\tSelect and prepare no more than four visualizations to support your analytic findings from (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b2521",
   "metadata": {},
   "source": [
    "# General View \n",
    "## Crimes across Year-Month "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb40f3a",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "    * Overall crimes in UK have a cyclic pattern with peak in mid year\n",
    "    * Overall crime total decreased during 2014 to 2016 comparing to rest of the years\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_by_month_group = crimes_df.groupby(['MONTH', ])\n",
    "all_crimes_by_month = crimes_by_month_group.count().sort('MONTH', desc('count'),)\n",
    "all_crimes_by_month_df = all_crimes_by_month.toPandas() # Converting to pandas for visualization\n",
    "plotlyLine(all_crimes_by_month_df, {'x':'MONTH', 'y':'count', 'title':'Fig 1. All Crimes between 2010 to 2021'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5430fd",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "* `Burglary` is in 5th position among all crimes sorted down in descending order of `#of Crimes`\n",
    "* Pattern of `Shoplifting`, `Burglary`, `Vehicle crime` & `Criminal damange and arson` are similar\n",
    "* `Other Crimes` initally seems to be miscategorized \n",
    "* `Violence and sexual offences` is increasing over time\n",
    "* `Anti-soical behaviour` trend keeps decreasing till 2019 and suddenly increases in 2020. Probably due to outrise in corona\n",
    "* Drugs have a constant trend over time\n",
    "* `Violent Crime` has a declining trend. Data is not available after Apr-2013\n",
    "* If `Violent Crime` and `Violence and sexual offences` are combined together, there is an upward trend. As of 2021, Crimes increased 3x times of 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04656fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparing crime types trend at month level\n",
    "\n",
    "\"\"\"\n",
    "crime_by_type_month_group = crimes_df.groupby(['MONTH', 'CRIME_TYPE']) \n",
    "crimes_by_month = crime_by_type_month_group.count().sort('MONTH', desc('count'),)\n",
    "crimes_by_month_df = crimes_by_month.toPandas() # Converting to pandas for visualization\n",
    "\n",
    "plotlyLine(crimes_by_month_df, {'x':'MONTH', 'y':'count'\n",
    "                                , 'color':'CRIME_TYPE'\n",
    "                                , 'title':'Fig 2. Trend of All Crime Types'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54673c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb2c1be",
   "metadata": {},
   "source": [
    "\n",
    "# Finding Burglary Crimes From Data \n",
    "\n",
    "### Checking Various Crimes Types\n",
    "\n",
    "Grouping crimes types together and taking count of crimes\n",
    "\n",
    "\n",
    "#### Observations:\n",
    "* Among all crimes, 6% is Burglary crimes\n",
    "* Drug crimes is bigger than weapon crimes\n",
    "* Anti-social behaviour is 2x of Violence and sexual offences \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f503d81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking Various Crimes Types\n",
    "\n",
    "\"\"\"\n",
    "Grouping crimes types together and taking count of crimes\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "crimes_by_type_group = crimes_df.groupby('CRIME_TYPE') \n",
    "crimes_df_groupby_df = crimes_by_type_group.count().sort(desc('count'))\n",
    "\n",
    "crime_type_df = crimes_df_groupby_df.toPandas() # Converting to pandas for visualization\n",
    "crime_type_df['CRIME_%'] = round((crime_type_df['count']/crime_type_df['count'].sum()) *100, 2)\n",
    "\n",
    "plotlyTreeMap(crime_type_df,  {'path':['CRIME_TYPE'], 'values':'count','title':'Fig 3. Proportion View Of Crimes'\n",
    "                               ,'hover_name':\"CRIME_TYPE\"\n",
    "                               , 'hover_data':['count','CRIME_%']})\n",
    "\n",
    "plotlyBar(crime_type_df, {'x':'CRIME_TYPE', 'y':'count', 'title':'Fig 4. Number of Crimes Cases by Type'\n",
    "                          ,'hover_name':\"CRIME_TYPE\"\n",
    "                          , 'hover_data':['count','CRIME_%']})\n",
    "display(crime_type_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3091258e",
   "metadata": {},
   "source": [
    "# 5. Selection, application, and reasoning behind use of statistical analysis and multiple evaluation measures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f258cc",
   "metadata": {},
   "source": [
    "# Burglary Protection \n",
    "## Client: Insurance company developing a highly segmented home insurance product\n",
    "\n",
    "### Claims to prove:\n",
    "1. There are more burglaries in more affulent areas\n",
    "2. Burglaries are increasing, decreasing, or are stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12114af0",
   "metadata": {},
   "source": [
    "# To prove the claims:\n",
    "#### 1. There are more burglaries in more affulent areas\n",
    "1. Approach: Rank the Area names based on total #of Burglary crimes over years\n",
    "    ## Observations:\n",
    "        1. Leeds, Birmingham, Sheffield, Bradford, Liverpool, Bristol, Manchester are top areas where the Burglary crimes\n",
    "        trends are high compared to other areas\n",
    "        2. We can create buckets / bins based on the ranks / #of crimes\n",
    "    \n",
    "\n",
    "#### 2. Burglaries are increasing, decreasing, or are stable\n",
    "1. Approach: Look at the trend of burglaries over time\n",
    "    ## Observations:\n",
    "    1. Cyclic trend of Burglary crimes is consistent & peaks during end of the year.\n",
    "    2. Between Jan 2014 and Mar 2019, the trend is $\\pm$ 3K crimes from the mean of 35K crimes\n",
    "    3. Burglary reduced by 70% comparing Jan 2020 and March 2020 due to [Covid-19 based on Timeline of UK government coronavirus lockdowns and measures, March 2020 to December 2021](https://www.instituteforgovernment.org.uk/sites/default/files/2022-12/timeline-coronavirus-lockdown-december-2021.pdf)\n",
    "    ## Conclusion:\n",
    "    #### 1. Forecasting of Burglary crimes are significantly skewed due to Covid-19 effect. \n",
    "    #### 2. If we negate the covid-19 period (2019 FY - 2021 FY), Burglary crimes started declining and became stable after Jan 2014.\n",
    "    #### 3. Across the timeline with crime peaking during end of Year\n",
    "    \n",
    "    \n",
    "2. Aggregate by area names and look at their trend\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb0895",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410b8a70",
   "metadata": {},
   "source": [
    "# Test Claim #1 \" Burglary Crime is increasing, decreasing ,or is stable\"\n",
    "### To prove the claim, \n",
    "1. Filter for CRIME_TYPE='Burglary'\n",
    "2. Look at trend over time\n",
    "3. Additional insight: Look at trend over time by LSOA Area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Filter for Burglary Crimes\n",
    "\n",
    "'''\n",
    "\n",
    "Burglary_crime_df = crimes_df.filter((col('CRIME_TYPE')=='Burglary'))\n",
    "\n",
    "Burglary_crime_by_year_area_df = Burglary_crime_df.groupby(['YEAR', 'AREA_NAME']).agg(count(col('MONTH')).alias('NUMBER_OF_CRIMES'))\n",
    "\n",
    "\n",
    "# Converting to pandas\n",
    "Burglary_crime_rank_df = Burglary_crime_by_year_area_df.select(*['AREA_NAME', 'YEAR', 'NUMBER_OF_CRIMES']).toPandas()\n",
    "\n",
    "# Adding Ranks based on descending order of `NUMBER_OF_CRIMES`  \n",
    "# Lower rank means highly populated with `Burglary crimes` in that Area\n",
    "\n",
    "Burglary_crime_rank_df['BURGLARY_CRIMES_RANK'] = Burglary_crime_rank_df.groupby(['YEAR'])['NUMBER_OF_CRIMES'].rank('first', ascending=False)\n",
    "Burglary_crime_rank_df['BURGLARY_CRIMES_RANK'] = Burglary_crime_rank_df['BURGLARY_CRIMES_RANK'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ee362",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('What are the top 20 Areas involving Burglary incidents?')\n",
    "\n",
    "print('Top 20 Burglary cases Based on BURGLARY_CRIMES_RANK')\n",
    "\n",
    "stylePandasDataframe(pd.pivot_table(Burglary_crime_rank_df[Burglary_crime_rank_df['BURGLARY_CRIMES_RANK']<21].fillna('Unknown Area Name')\n",
    "               , values=['AREA_NAME'], index=['YEAR',]\n",
    "               , columns=['BURGLARY_CRIMES_RANK']\n",
    "               , aggfunc='min', fill_value='', dropna=False, sort=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dfb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Burglary_crime_df_overall = Burglary_crime_df.groupby('AREA_NAME').agg(count(col('MONTH')).alias('NUMBER_OF_CRIMES'))\n",
    "Burglary_crime_df_overall_pdf = Burglary_crime_df_overall.toPandas()\n",
    "\n",
    "\n",
    "# Adding Ranks based on descending order of `NUMBER_OF_CRIMES`  \n",
    "# Lower rank means highly populated with `Burglary crimes` in that Area\n",
    "\n",
    "Burglary_crime_df_overall_pdf['OVERALL_BURGLARY_CRIMES_RANK'] = Burglary_crime_df_overall_pdf['NUMBER_OF_CRIMES'].rank(method='first', ascending=False)\n",
    "Burglary_crime_df_overall_pdf['OVERALL_BURGLARY_CRIMES_RANK'] = Burglary_crime_df_overall_pdf['OVERALL_BURGLARY_CRIMES_RANK'].astype(int)\n",
    "\n",
    "Burglary_crime_df_overall_pdf.fillna('Unknown Area Name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a9ee0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('What are the top 20 Areas involving Burglary incidents Across Years ?')\n",
    "\n",
    "print('Top 20 Burglary cases Based on OVERALL_BURGLARY_CRIMES_RANK')\n",
    "\n",
    "stylePandasDataframe(pd.pivot_table(Burglary_crime_df_overall_pdf[Burglary_crime_df_overall_pdf['OVERALL_BURGLARY_CRIMES_RANK']<21]\n",
    "               , values=['AREA_NAME']\n",
    "               , index=['OVERALL_BURGLARY_CRIMES_RANK']\n",
    "               , aggfunc='min', fill_value='', dropna=False, sort=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Burglary_crime_df_overall_pdf['Crime_Bins'] = pd.cut(Burglary_crime_df_overall_pdf['NUMBER_OF_CRIMES'], bins=10, labels=[f'Crime_Bin_{_}' for _ in range(1,11)],)\n",
    "\n",
    "Burglary_crime_df_overall_pdf.groupby(['Crime_Bins'], sort=True).agg(number_of_areas = pd.NamedAgg(column=\"AREA_NAME\", aggfunc=\"count\")\n",
    "    ,min_number_of_crime = pd.NamedAgg(column=\"NUMBER_OF_CRIMES\", aggfunc=\"min\")\n",
    "    , max_number_of_crime = pd.NamedAgg(column=\"NUMBER_OF_CRIMES\", aggfunc=\"max\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e855b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "print(\"Fig 5. Income estimates for small areas, England and Wales: financial year ending 2018\")\n",
    "\n",
    "IFrame('https://www.ons.gov.uk/visualisations/dvc767/map/index.html', width='100%', height='531px')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd385786",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. Forecasting of Burglary crimes are significantly skewed due to Covid-19 effect. \n",
    "2. If we negate the covid-19 period (2019 FY - 2021 FY), Burglary crimes started declining and became stable after Jan 2014.\n",
    "3. Across the timeline with crime peaking during end of Year\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Claim #2. Burglaries are increasing, decreasing, or are stable')\n",
    "print('Test 1: Check if Burglary Crimes is Increasing')\n",
    "\n",
    "Burglary_crimes_by_month_df = Burglary_crime_df.groupby(['MONTH',]).count().sort('MONTH', desc('count'),)\n",
    "Burglary_crimes_by_month_pdf = Burglary_crimes_by_month_df.toPandas()\n",
    "print('Burglary crime count mean value: ', Burglary_crimes_by_month_pdf['count'].mean())\n",
    "plotlyLine(Burglary_crimes_by_month_pdf, {'x':'MONTH', 'y':'count', 'title':'Fig 6. Claim #1. Burglary Crimes is Increasing'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Test 2: Check if \"Burglaries are increasing, decreasing, or are stable\" by LSOA Area')\n",
    "\n",
    "Burglary_crimes_by_area_month_df = Burglary_crime_df.groupby(['MONTH','AREA_NAME']).count().sort('AREA_NAME', 'MONTH', desc('count'),)\n",
    "Burglary_crimes_by_area_month_pdf = Burglary_crimes_by_area_month_df.toPandas()\n",
    "plotlyLine(Burglary_crimes_by_area_month_pdf.fillna('Unknown Area Name').sort_values(['MONTH', 'count', 'AREA_NAME'], ascending=False), {'x':'MONTH', 'y':'count'\n",
    "                                                       , 'animation_frame':'AREA_NAME'\n",
    "                                                       , 'animation_group':'AREA_NAME'\n",
    "                                                       ,'range_y':[0, 1200]\n",
    "                                                       , 'title':'Fig 7. Claim #2. \"Burglaries are increasing, decreasing, or are stable\" By LSOA Area'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a56405e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c3c802",
   "metadata": {},
   "source": [
    "### UK Geograpy - Burglary Density Heatmap Observations\n",
    "* Crimes are more in `Counties`\n",
    "* Crimes are highly dense in areas like London, Cardiff, Birmingham, Leeds, Manchester & coastal areas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c6af1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Map\n",
    "burglary_crimes_lat_long_crimes_df = Burglary_crime_df.groupby(['LATITUDE', 'LONGITUDE']).agg(psf.expr('count(MONTH) as BURGLARY_COUNT')).toPandas()\n",
    "\n",
    "burglary_crimes_map = folium.Map(location=[51.4203,0.0705], tiles='stamentoner', zoom_start=6)\n",
    "\n",
    "# Add a heatmap to the base map\n",
    "HeatMap(data=burglary_crimes_lat_long_crimes_df[['LATITUDE', 'LONGITUDE','BURGLARY_COUNT']].dropna(), radius=12, max_opacity=0.3).add_to(burglary_crimes_map)\n",
    "\n",
    "# Display the map\n",
    "print('Fig 8. Burglary Density Heatmap')\n",
    "burglary_crimes_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d628be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c32092a4",
   "metadata": {},
   "source": [
    "# Using Machine Learning To Forecast Crimes\n",
    "### Using Regression model to forecast  crimes related to (Violen crimes, weapon crimes & drug crimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparing Burglary crime types trend at month level\n",
    "Filter for Burglary Crimes\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "crimes_by_month = Burglary_crime_df.groupby(['MONTH', 'CRIME_TYPE']).count().sort('MONTH', desc('count'),)\n",
    "crimes_by_month_df = crimes_by_month.toPandas() # Converting to pandas for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotlyLine(crimes_by_month_df, {'x':'MONTH', 'y':'count', 'color':'CRIME_TYPE', 'title':'Fig 9. Trend of Burglary Crime'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b61100e",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis and consideration of the appropriateness of the solution for the initial problem\n",
    "\n",
    "### Observations:\n",
    "* **Filter:** We are narrowing down to 'Burglary' for forecasting \n",
    "* **Forecast to future:** 12 Month window \n",
    "* **Machine Learning Model:** Linear Regression \n",
    "\n",
    "### Model Performance:\n",
    "* The regression model was able to predict as close as possible\n",
    "* We can also try with various other regressor models like xgboost, catboost, lightgbm and so on.\n",
    "* Another approach is to go with Time series models like fbprophet, ARIMA, SARIMA models\n",
    "\n",
    "### Feature engineering:\n",
    "* When using Regression model, we need to create lags of target variable.\n",
    "    * Using lags, we can introduce seasonality in the data. \n",
    "    * This is one of the way, time series models use to create relationship behind the seasonality pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "burglary_crimes_month_df = Burglary_crime_df.groupby('MONTH').agg(count('MONTH').alias('NUMBER_OF_CRIMES')).sort(desc('MONTH'))\n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('TEMP', psf.lit(1))\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "windowSpec  = Window.partitionBy(\"TEMP\").orderBy(\"MONTH\")\n",
    "\n",
    "## Feature Engineering \n",
    "# Creation of lags to introduce seasonality\n",
    "# \n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('LAG1', psf.lag('NUMBER_OF_CRIMES',1).over(windowSpec))\n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('LAG2', psf.lag('NUMBER_OF_CRIMES',2).over(windowSpec))\n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('LAG3', psf.lag('NUMBER_OF_CRIMES',3).over(windowSpec))\n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('LAG4', psf.lag('NUMBER_OF_CRIMES',4).over(windowSpec))\n",
    "burglary_crimes_month_df = burglary_crimes_month_df.withColumn('LAG5', psf.lag('NUMBER_OF_CRIMES',5).over(windowSpec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values caused by lags\n",
    "full_model_data_df = burglary_crimes_month_df.dropna()\n",
    "\n",
    "# Using row number to create train test split \n",
    "full_model_data_df = full_model_data_df.withColumn('ROW_NUMBER', psf.row_number().over(windowSpec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485978f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 80% of data as training and remaining 20% as testing\n",
    "train_size = full_model_data_df.count()*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train & test\n",
    "\n",
    "train_data = full_model_data_df.filter(full_model_data_df.ROW_NUMBER<train_size)\n",
    "test_data = full_model_data_df.filter(full_model_data_df.ROW_NUMBER>=train_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e88c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Observation:\n",
    "    * The pattern is Number of crimes involving possession of weapons & Drugs.\n",
    "    * They form a U shape trend with increase in future.\n",
    "\n",
    "'''\n",
    "\n",
    "plotlyLine(burglary_crimes_month_df.toPandas(), {'x':'MONTH', 'y':'NUMBER_OF_CRIMES','title':'Fig 10. Trend of `Burglary`'}) #'color':'CRIME_TYPE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3ff32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af16db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_df = train_data.toPandas()\n",
    "train_data_df.set_index('MONTH', inplace=True)\n",
    "\n",
    "test_data_df = test_data.toPandas()\n",
    "test_data_df.set_index('MONTH', inplace=True)\n",
    "\n",
    "# Renaming variables & Selecting features for the model\n",
    "train_data_df['ACTUAL'] = train_data_df['NUMBER_OF_CRIMES']\n",
    "test_data_df['ACTUAL'] = test_data_df['NUMBER_OF_CRIMES']\n",
    "features = ['LAG1', 'LAG2', 'LAG3', 'LAG4', 'LAG5']\n",
    "train_data_df['TYPE'] = 'TRAIN'\n",
    "test_data_df['TYPE'] = 'TEST'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9bc719",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_df[[*features, 'ACTUAL']]\n",
    "y_train = X_train.pop('ACTUAL')\n",
    "X_test = test_data_df[[*features, 'ACTUAL']]\n",
    "y_test = X_test.pop('ACTUAL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict the forecast for the train & test data for plotting\n",
    "train_data_df['PREDICTED'] = model.predict(train_data_df[features])\n",
    "test_data_df['PREDICTED'] = model.predict(test_data_df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59283ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using mean squared error and R-squared\n",
    "\n",
    "'''\n",
    "\n",
    "MSE: Mean Squared Error (Thumb Rule: Lower is better)\n",
    "    Average(Square (difference between Actual and predicted))\n",
    "    \n",
    "RMSE: Root Mean Squared Error (Thumb Rule: Lower is better)\n",
    "    MSE penalizes larger errors more severely and taking Sqrt will reduce \n",
    "\n",
    "\n",
    "R-Squared = (Thumb Rule: Closer to 1 is better)\n",
    "    Proportion of variability of dependent variable explained by independent variable \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred) \n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'MSE: {mse:.2f}') # Lower the better\n",
    "print(f'RMSE: {rmse:.2f}') # Lower the better\n",
    "print(f'R-squared: {r2:.2f}') # Higher the better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5548d75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make forecasts for future time periods\n",
    "future_periods = 12\n",
    "future_data = test_data_df.copy()\n",
    "\n",
    "for period in range(1, future_periods+1):\n",
    "    feature_values = future_data[features].iloc[-1].values.reshape(1, -1)\n",
    "    forecast = model.predict(feature_values)[0]\n",
    "    \n",
    "    # Appending new row and making a lag shift for next input \n",
    "    future_data = future_data.append(pd.DataFrame({\n",
    "                                                    'PREDICTED': forecast\n",
    "                                                   , 'LAG1': forecast\n",
    "                                                   , 'LAG2': feature_values[0,0]\n",
    "                                                   , 'LAG3': feature_values[0,1]\n",
    "                                                   , 'LAG4': feature_values[0,2]\n",
    "                                                   , 'LAG5': feature_values[0,3]\n",
    "                                                   , 'TYPE':'FUTURE'}\n",
    "                                                  , index=[future_data.index[-1] + pd.DateOffset(months=1)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00899e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train, test & future forecast for plotting\n",
    "\n",
    "model_performance = pd.concat([train_data_df, future_data]).reset_index() \n",
    "model_performance['PREDICTED_TYPE'] = 'PREDICTED_'+model_performance['TYPE']\n",
    "model_performance['ERROR'] = model_performance['ACTUAL']-model_performance['PREDICTED']\n",
    "\n",
    "fig = px.line(model_performance, x='index', y='PREDICTED',color='PREDICTED_TYPE', title='Fig 11. Linear Regression Model Prediction vs ACTUAL')\n",
    "fig.add_scatter(x=model_performance['index'], y=model_performance['ACTUAL'], name='ACTUAL', mode='lines+markers', line={'dash':'dot'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b39cef",
   "metadata": {},
   "source": [
    "# Observations\n",
    "1. Forecasting of Burglary crimes are significantly skewed due to Covid-19 effect. \n",
    "2. If we negate the covid-19 period (2019 FY - 2021 FY), Burglary crimes started declining and became stable after Jan 2014.\n",
    "3. Looking at the model's performance on train & test, we are close with prediction & (r2 score of 0.55).\n",
    "4. Since (2019 FY - 2021 FY), Burglary crimes reports have reduced heavily. Yet, the model is able to recorrect the prediction with forecasts of increasing trend.\n",
    "5. If we negate Covid-19 effect, we would be expecting cases to follow same seasonal trend which the model is able to predict approximately \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Stopping Services / Memory Clean\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186ccc4",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Evaluation and Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec75d0",
   "metadata": {},
   "source": [
    "# Takeaway for the Insurance Company\n",
    "## Conclusion:\n",
    "\n",
    "#### 1. There are more burglaries in more affulent areas\n",
    "    1. Crimes are highly dense in areas like London, Cardiff, Birmingham, Leeds, Manchester & coastal areas\n",
    "    2. Leeds, Birmingham, Sheffield, Bradford, Liverpool, Bristol, Manchester are top areas where the Burglary crimes trends are high compared to other areas\n",
    "    3. We can create buckets / bins based on the ranks / #of crimes\n",
    "    4. Use of bucketing technique, we can create clusters containing areas which can be used to set policy price.\n",
    "       #### A better approach instead of Binning is **K-Means** Segmentation. \n",
    "            1. Create various features for the model \n",
    "            2. Score the areas \n",
    "            3. Between each model score runs, track how much data points are shifted from 1 segment to another\n",
    "            4. When the clusters are shifted drastically (say 10%-20% across clusters) then re-run **K-Means** model again\n",
    "\n",
    "#### 2. Burglary increasing, decreasing, or stable\n",
    "* Burglary Crimes are **stable**. \n",
    "* From 2011 to 2016, there is a downward trend and later June-2016 the trend started going back to normal \n",
    "(2014 pattern)\n",
    "* Based on _trend analysis over months & year_, we can conclude that Burglary crimes are **Stable** \n",
    "* Cyclic trend of Burglary crimes is consistent & peaks during end of the year.\n",
    "* Between Jan 2014 and Mar 2019, the trend is $\\pm$ 3K crimes from the mean of 35K crimes\n",
    "* Across the timeline with crime peaking during end of Year\n",
    "* Burglary reduced by 70% comparing Jan 2020 and March 2020 due to [Covid-19 based on Timeline of UK government coronavirus lockdowns and measures, March 2020 to December 2021](https://www.instituteforgovernment.org.uk/sites/default/files/2022-12/timeline-coronavirus-lockdown-december-2021.pdf)\n",
    "\n",
    "* Forecasting of Burglary crimes are significantly skewed due to Covid-19 effect. \n",
    "* If we negate the covid-19 period (2019 FY - 2021 FY), Burglary crimes started declining and became stable after\n",
    "Jan 2014.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ddc3f8",
   "metadata": {},
   "source": [
    "## 8. Scientific References and Citation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff4cdf",
   "metadata": {},
   "source": [
    "1. \"Crime Detection and Prediction Using Big Data Analytics: A Case Study of Chicago\" by Dong Wang, et al., published in IEEE Transactions on Big Data in 2018, https://www.jetir.org/papers/JETIR2107201.pdf\n",
    "\n",
    "2. \"Using Machine Learning to Assist Crime Prevention,\" 2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI), Hamamatsu, Japan, 2017, pp. 1029-1030, doi: 10.1109/IIAI-AAI.2017.46.\n",
    "\n",
    "3. Office for National Statistics (ONS), published 5 March 2020, ONS website, statistical bulletin, [Income estimates for small areas, England and Wales: financial year ending 2018](https://www.ons.gov.uk/peoplepopulationandcommunity/personalandhouseholdfinances/incomeandwealth/bulletins/smallareamodelbasedincomeestimates/financialyearending2018)\n",
    "\n",
    "\n",
    "4. Office for National Statistics. (2021). Crime in England and Wales. Retrieved from https://www.ons.gov.uk/peoplepopulationandcommunity/crimeandjustice/datasets/crimeinenglandandwales\n",
    "\n",
    "* Police.UK. (2021). Police.UK - Crime and Policing in England, Wales and Northern Ireland. Retrieved from https://www.police.uk/\n",
    "\n",
    "5. G. Jha, L. Ahuja and A. Rana, \"Criminal Behaviour Analysis and Segmentation using K-Means Clustering,\" 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), Noida, India, 2020, pp. 1356-1360, doi: 10.1109/ICRITO48877.2020.9197791.\n",
    "\n",
    "6. https://www.ons.gov.uk/economy/inflationandpriceindices/timeseries/l55o/mm23\n",
    "\n",
    "7. https://www.ons.gov.uk/economy/inflationandpriceindices/bulletins/consumerpriceinflation/march2023#:~:text=The%20CPIH%20inflation%20rate%20is,down%20from%2013.4%25%20in%20February.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
